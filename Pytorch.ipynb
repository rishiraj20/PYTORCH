{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iw4CslGg97DL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TENSORS**\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see Bridge with NumPy). Tensors are also optimized for automatic differentiation (we’ll see more about that later in the Autograd section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along!"
      ],
      "metadata": {
        "id": "y_3RSNsqSFSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a tensor from a Python List\n",
        "data = [\n",
        "        [0, 1], \n",
        "        [2, 3],\n",
        "        [4, 5]\n",
        "       ]\n",
        "x_python = torch.tensor(data)\n",
        "\n",
        "# Print the tensor\n",
        "x_python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKsn0c-NSEKJ",
        "outputId": "66ec60bc-728f-43ab-8221-85a7cd5c6364"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also call torch.tensor() with the optional dtype parameter, which will set the data type. Some useful datatypes to be familiar with are: torch.bool, torch.float, and torch.long.\n"
      ],
      "metadata": {
        "id": "ecbz2NlaSE32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_float = torch.tensor(data, dtype=torch.float)\n",
        "x_float\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcdJaDHfSXET",
        "outputId": "3ba7fd73-00da-47db-f2a8-0004fca4d769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.],\n",
              "        [4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_python.float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4cMJK6JTHHz",
        "outputId": "d1009fec-77a9-4fb0-cb6f-abc65c00799c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.],\n",
              "        [4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also initialize a tensor from a NumPy array."
      ],
      "metadata": {
        "id": "ZBVUK7RjTScV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize a tensor from a NumPy array\n",
        "ndarray = np.array(data)\n",
        "x_numpy = torch.from_numpy(ndarray)\n",
        "\n",
        "# Print the tensor\n",
        "x_numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk7qxdbbTMhb",
        "outputId": "1e98c2e9-a6f4-481b-aaff-eab7d97717c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also initialize a tensor from another tensor, using the following methods:\n",
        "\n",
        "**torch.ones_like(old_tensor)**: Initializes a tensor of 1s.\n",
        "**torch.zeros_like(old_tensor)**: Initializes a tensor of 0s.\n",
        "t**orch.rand_like(old_tensor**): Initializes a tensor where all the elements are sampled from a uniform distribution between 0 and 1.\n",
        "**torch.randn_like(old_tensor)**: Initializes a tensor where all the elements are sampled from a normal distribution.\n",
        "All of these methods preserve the tensor properties of the original tensor passed in, such as the shape and device, which we will cover in a bit."
      ],
      "metadata": {
        "id": "z0VCmLr7TcbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a base tensor\n",
        "x = torch.tensor([[1., 2.], [3., 4.]])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTl51QswTa5S",
        "outputId": "6866c441-1ec7-4766-d556-02c203d04a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_zeros = torch.zeros_like(x)\n",
        "x_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLQfXA4EUdN6",
        "outputId": "60e11289-5856-474c-fb87-9c06a0077390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a tensor where each element is sampled from a uniform distribution\n",
        "# between 0 and 1\n",
        "x_rand = torch.rand_like(x)\n",
        "x_rand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpRNwNgJUjKH",
        "outputId": "921c7cab-5381-4b4a-cd67-f66a083b2fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5282, 0.0262],\n",
              "        [0.7543, 0.9231]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Specifying a Shape\n",
        "We can also instantiate tensors by specifying their shapes (which we will cover in more detail in a bit). The methods we could use follow the ones in the previous section:\n",
        "\n",
        "torch.zeros()\n",
        "torch.ones()\n",
        "torch.rand()\n",
        "torch.randn()"
      ],
      "metadata": {
        "id": "IbPe5t5nVbTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a 2x3x2 tensor of 0s\n",
        "shape = (4, 2, 2)\n",
        "x_zeros = torch.zeros(shape) # x_zeros = torch.zeros(4, 3, 2) is an alternative\n",
        "x_zeros\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um9ZwBgDVdhG",
        "outputId": "7769c558-955c-4d27-8f98-8baccee61b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor Properties\n",
        "Data Type\n",
        "The dtype property lets us see the data type of a tensor.\n",
        "Shape\n",
        "The shape property tells us the shape of our tensor. This can help us identify how many dimensional our tensor is as well as how many elements exist in each dimension."
      ],
      "metadata": {
        "id": "YvuBFbeWZd38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(3, 2)\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zptCjM1lZ1sh",
        "outputId": "c489e71a-0053-4cc3-a519-fa8c6c895bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a 3x2 tensor, with 3 rows and 2 columns\n",
        "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x.shape[0])\n",
        "print(x.size(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcp9P0F8aMY5",
        "outputId": "9581ecaf-363d-4ba7-b69c-93c320741b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "torch.Size([3, 2])\n",
            "3\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can change the shape of a tensor with the view() method.\n",
        "# Example use of view()\n",
        "# x_view shares the same memory as x, so changing one changes the other\n",
        "x_view = x.view(3, 2)\n",
        "print(x_view)\n",
        "x_view = x.view(-1, 3)\n",
        "print(x_view)\n",
        "# Change the shape of x to be 3x2\n",
        "# x_reshaped could be a reference to or copy of x\n",
        "x_reshaped = torch.reshape(x, (2, 3))\n",
        "print(x_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKdAtCECa7pS",
        "outputId": "456ee768-44b6-4094-85b3-e9ab6092cb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a 5x2 tensor, with 5 rows and 2 columns\n",
        "x = torch.arange(10).reshape(5, 2)\n",
        "print(x)\n",
        "\n",
        "# Add a new dimension of size 1 at the 1st dimension\n",
        "x = x.unsqueeze(1)\n",
        "print(x.shape)\n",
        "\n",
        "# Squeeze the dimensions of x by getting rid of all the dimensions with 1 element\n",
        "x = x.squeeze()\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWb0p1b0cNFW",
        "outputId": "3bac9c7a-6fd0-44a0-9e6f-d2ce7da232e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7],\n",
            "        [8, 9]])\n",
            "torch.Size([5, 1, 2])\n",
            "torch.Size([5, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Device**\n",
        "Device property tells PyTorch where to store our tensor. Where a tensor is stored determines which device, GPU or CPU, would be handling the computations involving it. We can find the device of a tensor with the device property."
      ],
      "metadata": {
        "id": "zQyz-gxxcr7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor([[1, 2], [3, 4]])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKZDvNl2cwgD",
        "outputId": "12cf9894-e926-499a-c798-afeaecc0b3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ej3OMqYdFHc",
        "outputId": "8f170ff9-ceac-4314-8697-0135e3aa448e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can move a tensor from one device to another with the method to(device).\n",
        "# Check if a GPU is available, if so, move the tensor to the GPU\n",
        "if torch.cuda.is_available():\n",
        "  x.to('cuda') "
      ],
      "metadata": {
        "id": "WPW_9cXgdHXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Indexing**\n",
        "In PyTorch we can index tensors, similar to NumPy."
      ],
      "metadata": {
        "id": "UpsGKDbxeN_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor([\n",
        "                  [[1, 2], [3, 4]],\n",
        "                  [[5, 6], [7, 8]], \n",
        "                  [[9, 10], [11, 12]] \n",
        "                 ])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x[0])\n",
        "print(x[:, 0, 0])\n",
        "print(x[0, 0, 0].item()) #prints scalar value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDzKUuGsm2-S",
        "outputId": "1f2828a8-2aae-472c-d1de-0c65febbc643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.]],\n",
            "\n",
            "        [[ 5.,  6.],\n",
            "         [ 7.,  8.]],\n",
            "\n",
            "        [[ 9., 10.],\n",
            "         [11., 12.]]])\n",
            "torch.Size([3, 2, 2])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([1., 5., 9.])\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Operations**\n",
        "PyTorch operations are very similar to those of **NumPy**. We can work with both scalars and other tensors."
      ],
      "metadata": {
        "id": "Efx5mIsdoDsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an example tensor\n",
        "x = torch.ones((3,2,2))\n",
        "print(x)\n",
        "print(x+2)\n",
        "print(x*3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ15W6LvoLWC",
        "outputId": "766adbb2-2b9b-4943-90c6-0750d849f8bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.]]])\n",
            "tensor([[[3., 3.],\n",
            "         [3., 3.]],\n",
            "\n",
            "        [[3., 3.],\n",
            "         [3., 3.]],\n",
            "\n",
            "        [[3., 3.],\n",
            "         [3., 3.]]])\n",
            "tensor([[[3., 3.],\n",
            "         [3., 3.]],\n",
            "\n",
            "        [[3., 3.],\n",
            "         [3., 3.]],\n",
            "\n",
            "        [[3., 3.],\n",
            "         [3., 3.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones((4,3)) * 6\n",
        "print(a)\n",
        "\n",
        "b = torch.ones(3) * 2\n",
        "b\n",
        "\n",
        "c = a @ b \n",
        "\n",
        "print(c)\n",
        "print(c.size())\n",
        "print(c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_bnXFl-pKI0",
        "outputId": "05a7375f-98f4-43ff-d956-668e7f83dd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 6., 6.],\n",
            "        [6., 6., 6.],\n",
            "        [6., 6., 6.],\n",
            "        [6., 6., 6.]])\n",
            "tensor([36., 36., 36., 36.])\n",
            "torch.Size([4])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B8v6lqlKw2iD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#operations on mean median mode"
      ],
      "metadata": {
        "id": "j0UtdGBXszbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Autograd**\n",
        "PyTorch and other machine learning libraries are known for their automatic differantiation feature. That is, given that we have defined the set of operations that need to be performed, the framework itself can figure out how to compute the gradients. We can call the backward() method to ask PyTorch to calculate the gradiends, which are then stored in the grad attribute.\n"
      ],
      "metadata": {
        "id": "sEzOD3ocs5uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an example tensor\n",
        "# requires_grad parameter tells PyTorch to store gradients\n",
        "x = torch.tensor([2.], requires_grad=True)\n",
        "\n",
        "print(x)\n",
        "# Print the gradient if it is calculated\n",
        "# Currently None since x is a scalar\n",
        "print(x.grad)\n",
        "\n",
        "\n",
        "# Calculating the gradient of y with respect to x\n",
        "y = x * x * 3 # 3x^2\n",
        "print(y)\n",
        "y.backward()\n",
        "print(x.grad) # d(y)/d(x) = d(3x^2)/d(x) = 6x = 12\n",
        "\n",
        "z = x * x * 3 # 3x^2\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QPet-Mpx93U",
        "outputId": "1d04095d-a27e-418e-dcb6-4be19b5efe48"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.], requires_grad=True)\n",
            "None\n",
            "tensor([12.], grad_fn=<MulBackward0>)\n",
            "tensor([12.])\n",
            "tensor([24.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network Module\n",
        "\n",
        "So far we have looked into the tensors, their properties and basic operations on tensors\n",
        "\n",
        "C we will use predefined blocks in the torch.nn module of PyTorch. We will then put together these blocks to create complex networks"
      ],
      "metadata": {
        "id": "ts_3qlps3RFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "WdMz-7Ka3QAZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_1 = nn.Linear(20,30)\n",
        "input = torch.randn(128,20)\n",
        "output =layer_1(input)\n",
        "print(output.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge4UM51grXYf",
        "outputId": "a88665af-76f7-4395-c5e1-2c1df9aed974"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the inputs\n",
        "input = torch.ones(2,3,4)\n",
        "print(input)\n",
        "# Make a linear layers transforming N,*,H_in dimensinal inputs to N,*,H_out\n",
        "# dimensional outputs\n",
        "linear = nn.Linear(4, 2)\n",
        "linear_output = linear(input)\n",
        "linear_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTemxDOtpUf2",
        "outputId": "40dcf30f-8174-4f02-a1f4-9ca2d9aa3bdc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.8355, -0.6406],\n",
              "         [-0.8355, -0.6406],\n",
              "         [-0.8355, -0.6406]],\n",
              "\n",
              "        [[-0.8355, -0.6406],\n",
              "         [-0.8355, -0.6406],\n",
              "         [-0.8355, -0.6406]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other Module Layers\n",
        "\n",
        "There are several other preconfigured layers in the nn module. Some commonly used examples are **nn.Conv2d**, **nn.ConvTranspose2d**, **nn.BatchNorm1d**, **nn.BatchNorm2d**,** nn.Upsample** and **nn.MaxPool2d** among many others. We will learn more about these as we progress in the course. For now, the only important thing to remember is that we can treat each of these layers as plug and play components: we will be providing the required dimensions and PyTorch will take care of setting them up."
      ],
      "metadata": {
        "id": "8KDvUAAz4BRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_output"
      ],
      "metadata": {
        "id": "JBSB2tcUzfoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting the Layers Together\n",
        "So far we have seen that we can create layers and pass the output of one as the input of the next. Instead of creating intermediate tensors and passing them around, we can use nn.Sequentual, which does exactly that."
      ],
      "metadata": {
        "id": "lL2bd7MZ3QRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block = nn.Sequential(\n",
        "    nn.Linear(4, 2),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "input = torch.ones(2,3,4)\n",
        "output = block(input)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTigw2sPnOyW",
        "outputId": "c9e95b74-90fb-4cdb-d240-ec5c35e9858d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5708, 0.3248],\n",
              "         [0.5708, 0.3248],\n",
              "         [0.5708, 0.3248]],\n",
              "\n",
              "        [[0.5708, 0.3248],\n",
              "         [0.5708, 0.3248],\n",
              "         [0.5708, 0.3248]]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Modules"
      ],
      "metadata": {
        "id": "GMj4YtSxnhKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultilayerPerceptron(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    # Call to the __init__ function of the super class\n",
        "    super(MultilayerPerceptron, self).__init__()\n",
        "\n",
        "    # Bookkeeping: Saving the initialization parameters\n",
        "    self.input_size = input_size \n",
        "    self.hidden_size = hidden_size \n",
        "\n",
        "    # Defining of our model\n",
        "    # There isn't anything specific about the naming of `self.model`. It could\n",
        "    # be something arbitrary.\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input_size, self.hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(self.hidden_size, self.input_size),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "vasfr9Kkpa3E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultilayerPerceptron(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    # Call to the __init__ function of the super class\n",
        "    super(MultilayerPerceptron, self).__init__()\n",
        "\n",
        "    # Bookkeeping: Saving the initialization parameters\n",
        "    self.input_size = input_size \n",
        "    self.hidden_size = hidden_size \n",
        "\n",
        "    # Defining of our layers\n",
        "    self.linear = nn.Linear(self.input_size, self.hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(self.hidden_size, self.input_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    linear = self.linear(x)\n",
        "    relu = self.relu(linear)\n",
        "    linear2 = self.linear2(relu)\n",
        "    output = self.sigmoid(linear2)\n",
        "    return output"
      ],
      "metadata": {
        "id": "boUlv4VHpevc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(2, 5)\n",
        "\n",
        "# Create our model\n",
        "model = MultilayerPerceptron(5, 3)\n",
        "\n",
        "# Pass our input through our model\n",
        "model(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp4iCk01phuI",
        "outputId": "f97fe449-c9a7-4273-d22e-99a65c06fb14"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5821, 0.4073, 0.6553, 0.5739, 0.5269],\n",
              "        [0.6351, 0.4251, 0.6537, 0.5203, 0.4405]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.named_parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwqG9_yHpj00",
        "outputId": "eceebcbc-e1a4-4268-8db2-538bd9d3a35e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('linear.weight', Parameter containing:\n",
              "  tensor([[-0.1863,  0.3020, -0.4289,  0.4208, -0.2215],\n",
              "          [ 0.3623, -0.1560,  0.2063, -0.3043,  0.2970],\n",
              "          [-0.4134,  0.3484, -0.3711, -0.3209,  0.1522]], requires_grad=True)),\n",
              " ('linear.bias', Parameter containing:\n",
              "  tensor([-0.4461,  0.4108, -0.3960], requires_grad=True)),\n",
              " ('linear2.weight', Parameter containing:\n",
              "  tensor([[ 0.2067, -0.4380,  0.5084],\n",
              "          [ 0.1321,  0.0936,  0.0879],\n",
              "          [ 0.1349,  0.5425, -0.5662],\n",
              "          [-0.3167, -0.0051, -0.3521],\n",
              "          [-0.5361, -0.1158,  0.3384]], requires_grad=True)),\n",
              " ('linear2.bias', Parameter containing:\n",
              "  tensor([ 0.4122, -0.3925,  0.5426,  0.2989,  0.1292], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimization\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# Create the y data\n",
        "y = torch.ones(10, 5)\n",
        "\n",
        "# Add some noise to our goal y to generate our x\n",
        "# We want out model to predict our original data, albeit the noise\n",
        "x = y + torch.randn_like(y)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTeXMUsdvvbO",
        "outputId": "837bc6b4-dd58-4ce7-e48d-6ed4d7e623aa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.6953,  1.0192,  1.9463, -0.1134,  1.0221],\n",
              "        [ 0.3469,  1.0425,  0.8886,  0.5200,  2.8855],\n",
              "        [ 0.5029,  0.2115,  0.5042,  0.1324,  0.7710],\n",
              "        [ 0.5735,  1.1654,  1.2412,  0.3652,  1.9605],\n",
              "        [ 1.8078,  1.7369,  0.9938,  1.7352,  0.1917],\n",
              "        [ 0.6266, -0.9348, -0.9005,  0.0607,  2.0082],\n",
              "        [ 0.1749, -1.0601,  1.4675,  2.7334,  0.5334],\n",
              "        [ 1.5671, -0.7165,  0.7894, -0.5623,  1.6371],\n",
              "        [ 1.4686,  0.7532,  0.4516, -0.5326,  0.3501],\n",
              "        [-0.4979,  0.0860, -1.6576,  2.5388,  1.0513]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = MultilayerPerceptron(5, 3)\n",
        "\n",
        "# Define the optimizer\n",
        "adam = optim.Adam(model.parameters(), lr=1e-1)\n",
        "\n",
        "# Define loss using a predefined loss function\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "# Calculate how our model is doing now\n",
        "y_pred = model(x)\n",
        "loss_function(y_pred, y).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHcYMIFbwqGX",
        "outputId": "b464164d-8d6a-49de-c917-15b1eb1640f7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8663741946220398"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of epoch, which determines the number of training iterations\n",
        "n_epoch = 10 \n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  # Set the gradients to 0\n",
        "  adam.zero_grad()\n",
        "\n",
        "  # Get the model predictions\n",
        "  y_pred = model(x)\n",
        "\n",
        "  # Get the loss\n",
        "  loss = loss_function(y_pred, y)\n",
        "\n",
        "  # Print stats\n",
        "  print(f\"Epoch {epoch}: traing loss: {loss}\")\n",
        "\n",
        "  # Compute the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # Take a step to optimize the weights\n",
        "  adam.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl2peSqUwxsH",
        "outputId": "00e5a774-7c19-40f0-e4de-c73b5795c56c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: traing loss: 0.8663741946220398\n",
            "Epoch 1: traing loss: 0.6335042715072632\n",
            "Epoch 2: traing loss: 0.48572659492492676\n",
            "Epoch 3: traing loss: 0.3596430718898773\n",
            "Epoch 4: traing loss: 0.2563168406486511\n",
            "Epoch 5: traing loss: 0.17937031388282776\n",
            "Epoch 6: traing loss: 0.1238587275147438\n",
            "Epoch 7: traing loss: 0.08251111209392548\n",
            "Epoch 8: traing loss: 0.05386689305305481\n",
            "Epoch 9: traing loss: 0.03442545607686043\n"
          ]
        }
      ]
    }
  ]
}